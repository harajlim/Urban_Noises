{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed libraries\n",
    "\n",
    "import librosa as lb #used for feature extracion and resampling\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display #builds on matplotlib to draw nice spectrograms.\n",
    "import IPython.display as ipd #used to play .wav files from notebook\n",
    "import pandas as pd \n",
    "# from scipy.io import wavfile #can be used to import .wav files but does not work on 24 bit depth audio files\n",
    "\n",
    "\n",
    "import soundfile as sf #soundfile enables loading 24 bit depth audio files.\n",
    "import time #used to measure code runtime. \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bottleneck in this code is reading the audio file. A single read on my machine takes approximately 0.23 seconds. \n",
    "Loading the entire ~5400 wav files takes approximately: 20 minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to be used in this exercise:\n",
    "\n",
    "#function to read wave file and get numpy file:\n",
    "\n",
    "def ReadAudio(filename):\n",
    "    x,sr=sf.read(filename)\n",
    "    x=x.T #transpose to match format of librosa array representation\n",
    "    #set sample rate at 22050 to reduce memory usage. \n",
    "    x=lb.resample(x,sr,22050)\n",
    "        \n",
    "    #change any stereo audio to mono.\n",
    "    if x.shape[0]==2:\n",
    "        x=lb.to_mono(x)\n",
    "     \n",
    "    #change to a list.\n",
    "    x=list(x)\n",
    "    return x,22050\n",
    "\n",
    "#function to find max number of samples over all sound files. Didnt end up using this since it is memory inefficient.\n",
    "#as Sounds would have to be stored in memory. \n",
    "def SampleNumbersMax(Sounds):\n",
    "    #Sounds in a list of lists.\n",
    "    maxNow=0\n",
    "    for sound in Sounds:\n",
    "        if len(sound)>maxNow:\n",
    "            maxNow=len(sound)\n",
    "    return maxNow\n",
    "\n",
    "#function to check length of sound file (number of samples) and increase it till it is equal to input numSamples\n",
    "def IncreaseNumSamples(sound,numSamples):\n",
    "    if len(sound)<numSamples:\n",
    "        newSound=sound+[0]*(numSamples-len(sound))\n",
    "    else:\n",
    "        newSound=sound\n",
    "    return newSound\n",
    "\n",
    "#function that takes all sounds and makes them all of equal length: also didnt use this to avoid storing Souds.\n",
    "def MakeAllEqualLength(Sounds,numSamples):\n",
    "    NewSounds=[]\n",
    "    for sound in Sounds:\n",
    "        NewSounds.append(IncreaseNumSamples(sound,numSamples))\n",
    "    return NewSounds\n",
    "    \n",
    "\n",
    "\n",
    "#function to extract Features:\n",
    "def getFeatures(Sound):\n",
    "    \n",
    "    stft=np.abs(lb.stft(Sound))\n",
    "    mfccs=np.mean(lb.feature.mfcc(y=Sound,sr=22050,n_mfcc=40).T,axis=0)\n",
    "    chroma=np.mean(lb.feature.chroma_stft(S=stft,sr=22050).T,axis=0)\n",
    "    mel=np.mean(lb.feature.melspectrogram(Sound,sr=22050).T,axis=0)\n",
    "    contrast = np.mean(lb.feature.spectral_contrast(S=stft, sr=22050).T,axis=0)\n",
    "    tonnetz = np.mean(lb.feature.tonnetz(y=librosa.effects.harmonic(Sound),sr=22050).T,axis=0)\n",
    "\n",
    "\n",
    "    return mfccs,chroma,mel,contrast,tonnetz\n",
    "\n",
    "def getFeatures1(Sound):\n",
    "\n",
    "    C1=lb.feature.chroma_stft(np.array(Sound),sr=22050,hop_length=5000) #see librosa features\n",
    "    C1=np.reshape(C1,(C1.shape[0]*C1.shape[1],))\n",
    "    \n",
    "    return C1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#unpack training Data IDs and labels\n",
    "\n",
    "Labels=pd.read_csv('train.csv')\n",
    "\n",
    "#change to numpy array\n",
    "Labels=np.array(Labels)\n",
    "\n",
    "\n",
    "#Build list of IDs and Classes, obeservation with ID ID[i] is in class Class[i]\n",
    "ID=[]\n",
    "Class=[]\n",
    "\n",
    "#unpack labels to IDs and Classes\n",
    "for val in Labels:\n",
    "    idnow,classnow=val\n",
    "    ID.append(idnow)\n",
    "    Class.append(classnow)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serialize all training wav files:\n",
    "\n",
    "#for ids in ID:\n",
    "#    x,sr=ReadAudio('train/'+str(ids)+'.wav')\n",
    "#    x=IncreaseNumSamples(x,88375)\n",
    "#    with open('train_pickle/'+str(ids)+'.pickle','wb') as handle:\n",
    "#       pickle.dump(x, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#unpack testing Data IDs\n",
    "\n",
    "Labels=pd.read_csv('test.csv')\n",
    "\n",
    "#change to numpy array\n",
    "Labels=np.array(Labels)\n",
    "\n",
    "\n",
    "#Build list of IDs and Classes, obeservation with ID ID[i] is in class Class[i]\n",
    "IDtest=[]\n",
    "\n",
    "\n",
    "#unpack labels to IDs and Classes\n",
    "for val in Labels:\n",
    "    idnow=int(val)\n",
    "    IDtest.append(idnow)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serialize all testing wav files:\n",
    "\n",
    "#for ids in IDtest:\n",
    "#    x,sr=ReadAudio('test/'+str(ids)+'.wav')\n",
    "#    x=IncreaseNumSamples(x,88375)\n",
    "#    with open('test_pickle/'+str(ids)+'.pickle','wb') as handle:\n",
    "#        pickle.dump(x, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find max sample count of any Sound: no need anymore, as have run and found maxNow (max number of samples till now)=88375\n",
    "#maxNow=0\n",
    "#start=time.time()\n",
    "\n",
    "#for ids in ID:\n",
    " #       \n",
    "  #      x,sr=ReadAudio('Train/'+str(ids)+'.wav')\n",
    "   #     if len(x)>maxNow:\n",
    "    #        maxNow=len(x)\n",
    "       \n",
    "#endtime=time.time()\n",
    "#print(-start+endtime)\n",
    "\n",
    "#maxNow turns out to be 88375\n",
    "#time elapsed for all data=1312 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique classes and keep reference vector\n",
    "Classes=set(Class)\n",
    "Classes=list(Classes) #the reference list of classes. A class of i will be translated to Classes[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marwan\\Anaconda3\\lib\\site-packages\\librosa\\core\\pitch.py:145: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n"
     ]
    }
   ],
   "source": [
    "#get training features\n",
    "\n",
    "features=[]\n",
    "for ids in ID:\n",
    "    \n",
    "    with open('train_pickle/'+str(ids)+'.pickle', 'rb') as handle:\n",
    "        x = pickle.load(handle)\n",
    "        a,b,c,d,e=getFeatures(np.array(x))\n",
    "        \n",
    "        \n",
    "    \n",
    "    features.append(np.hstack((a,b,c,d,e)))\n",
    "\n",
    "features=np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WeTryThe getFeatures function:\n",
    "\n",
    "#features=[]\n",
    "#for ids in ID:\n",
    "    \n",
    "#    with open('train_pickle/'+str(ids)+'.pickle', 'rb') as handle:\n",
    "#        x = pickle.load(handle)\n",
    "        \n",
    "    \n",
    "#    features.append(getFeatures(x))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#features=np.array(features)\n",
    "#features.shape\n",
    "\n",
    "\n",
    "trainFeatures=features[:,:]\n",
    "#testFeatures=features[4000:,:]\n",
    "features=[]\n",
    "\n",
    "trainLabels=Class[:]\n",
    "#testLabels=Class[4000:]\n",
    "\n",
    "#change labels from names to 0,1,...,9\n",
    "for i in range(len(trainLabels)):\n",
    "    trainLabels[i]=Classes.index(trainLabels[i])\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(100,100,100), random_state=1)\n",
    "#clf.fit(trainFeatures, trainLabels)     \n",
    "\n",
    "\n",
    "#PredictedLabels=clf.predict(testFeatures)\n",
    "\n",
    "#print(100*np.mean(PredictedLabels==testLabels))\n",
    "#percent times predicts correct with using getFeatures to get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 50, 50), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if no change to features\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(100,50,50), random_state=1)\n",
    "clf.fit(trainFeatures, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marwan\\Anaconda3\\lib\\site-packages\\librosa\\core\\pitch.py:145: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n"
     ]
    }
   ],
   "source": [
    "#Get features of Testing DATA:\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "featuresTest=[]\n",
    "for ids in IDtest:\n",
    "    \n",
    "    with open('test_pickle/'+str(ids)+'.pickle', 'rb') as handle:\n",
    "        x = pickle.load(handle)\n",
    "        a,b,c,d,e=getFeatures(np.array(x))\n",
    "        \n",
    "        \n",
    "    \n",
    "    featuresTest.append(np.hstack((a,b,c,d,e)))\n",
    "\n",
    "featuresTest=np.array(featuresTest)\n",
    "\n",
    "\n",
    "PredictedLabels=clf.predict(featuresTest)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if no change to features\n",
    "PredictedLabels=clf.predict(featuresTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Export=[]\n",
    "for index, lab in enumerate(PredictedLabels):\n",
    "    Export.append([str(Classes[lab])+','+str(IDtest[index])])\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "csvfile = \"results.csv\"\n",
    "\n",
    "#Assuming res is a flat list\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n',quoting=csv.QUOTE_NONE,quotechar='',escapechar='/')\n",
    "    for val in Export:\n",
    "        writer.writerow(val) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this to hear Audio of File Desired\n",
    "\n",
    "ipd.Audio('Train/193.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this to check what variables still available, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
